{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import random as rn\n",
    "from scipy.spatial import distance\n",
    "from scipy import stats\n",
    "from scipy.stats import expon\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from urllib.request import urlopen\n",
    "import json\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "year_before = 2015\n",
    "year_after = 2018"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_traits = pd.read_csv('Data_sets/Aggregated_network_attributes_period_'+str(year_before)+'.csv', index_col=False)\n",
    "df_traits['Household Size'] = df_traits['Household Size'].div(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_hesitancy = pd.read_csv('Data_sets/Aggregated_network_hesitancy_level_period_'+str(year_before)+'-'+str(year_after)+'.csv', index_col=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_facebook_friendship = pd.read_csv('Data_sets/Aggregated_facebook_network_period_'+str(year_before)+'-'+str(year_after)+'.csv', index_col=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_proximity = pd.read_csv('Data_sets/Aggregated_spatial_network_period_'+str(year_before)+'-'+str(year_after)+'.csv', index_col=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "######################################################################################################################\n",
    "######################################################################################################################\n",
    "######################################################################################################################\n",
    "######################################################################################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CREATE NETWORKS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spatial_network = nx.from_pandas_edgelist(df_proximity, source = 'source', target = 'target')\n",
    "spatial_network.remove_edges_from(list(nx.selfloop_edges(spatial_network)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "facebook_network = nx.from_pandas_edgelist(df_facebook_friendship, source = 'source', target = 'target')\n",
    "facebook_network.remove_edges_from(list(nx.selfloop_edges(facebook_network)))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spatial_network.add_nodes_from([each_node for each_node in facebook_network.nodes if each_node not in spatial_network.nodes]) \n",
    "facebook_network.add_nodes_from([each_node for each_node in spatial_network.nodes if each_node not in facebook_network.nodes]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nodes = list(df_traits['FIPS'])\n",
    "income_dict = dict(zip(nodes, list(df_traits['High Income'])))\n",
    "household_dict = dict(zip(nodes, list(df_traits['Household Size'])))\n",
    "\n",
    "nodes = list(df_hesitancy['FIPS'])\n",
    "hesitancy_before_dict = dict(zip(nodes, list(df_hesitancy['Hesitancy level before'])))\n",
    "hesitancy_after_dict = dict(zip(nodes, list(df_hesitancy['Hesitancy level after'])))\n",
    "opinion_before_dict = dict(zip(nodes, list(df_hesitancy['Opinion before'])))\n",
    "opinion_after_dict = dict(zip(nodes, list(df_hesitancy['Opinion after'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ASIGN ATTRIBUTES TO COUNTIES SPATIAL NETWORK\n",
    "dict_list = [income_dict,household_dict, hesitancy_before_dict,\\\n",
    "             hesitancy_after_dict,opinion_before_dict,opinion_after_dict]\n",
    "\n",
    "names = [\"High Income\",\"Household Size\",\"Hesitancy Level before\",\\\n",
    "         \"Hesitancy Level after\",\"Opinion Level before\",\"Opinion Level after\"]\n",
    "\n",
    "for each_attribute in range(0,6): \n",
    "    \n",
    "    # ASIGN ATTRIBUTES TO COUNTIES SPATIAL NETWORK\n",
    "    nx.set_node_attributes(spatial_network,dict_list[each_attribute],names[each_attribute])\n",
    "    # ASIGN ATTRIBUTES TO COUNTIES FACEBOOK NETWORK\n",
    "    nx.set_node_attributes(facebook_network,dict_list[each_attribute],names[each_attribute])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "######################################################################################################################\n",
    "######################################################################################################################\n",
    "######################################################################################################################\n",
    "######################################################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_parameters = pd.DataFrame(columns = ['Years','Data','Parameter value','Realization'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "######################################################################################################################\n",
    "######################################################################################################################\n",
    "######################################################################################################################\n",
    "######################################################################################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BOOTSTRAP METHOD TO MEASURE EMPIRICAL SOCIAL SELECTION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RANDOM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for realization in range(1,1000):\n",
    "    \n",
    "    bootstrap_random_network = facebook_network.copy()\n",
    "    \n",
    "    income_shuffle = rn.sample(list(df_traits['High Income']),len(list(df_traits['High Income'])))\n",
    "    household_shuffle = rn.sample(list(df_traits['Household Size']),len(list(df_traits['Household Size'])))\n",
    "    \n",
    "    income_dict = dict(zip(nodes, income_shuffle))\n",
    "    household_dict = dict(zip(nodes, household_shuffle))\n",
    " \n",
    "    nx.set_node_attributes(bootstrap_random_network, income_dict, 'High Income')\n",
    "    nx.set_node_attributes(bootstrap_random_network, household_dict, 'Household Size')\n",
    "\n",
    "    \n",
    "    xi, xj = [], []\n",
    "    for i,j in bootstrap_random_network.edges:\n",
    "        xi.append([bootstrap_random_network.nodes[i]['High Income'], bootstrap_random_network.nodes[i]['Household Size']])\n",
    "        xj.append([bootstrap_random_network.nodes[j]['High Income'], bootstrap_random_network.nodes[j]['Household Size']])   \n",
    "    \n",
    "    income = [bootstrap_random_network.nodes[i]['High Income'] for i in bootstrap_random_network.nodes]    \n",
    "    house  = [bootstrap_random_network.nodes[i]['Household Size'] for i in bootstrap_random_network.nodes] \n",
    "    corr   = np.cov(income,house)\n",
    "    vi     = np.linalg.inv(corr)        \n",
    "    \n",
    "    distances = [ distance.mahalanobis( xi[i], xj[i], vi ) for i in range(len(xj)) ]\n",
    "    \n",
    "    random_distance = sum(distances)/len(distances)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## REAL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "porcentaje = int(0.3 * facebook_network.number_of_nodes())\n",
    "nodes = [each_node for each_node in facebook_network.nodes()]\n",
    "\n",
    "for realization in range(1,1000):\n",
    "    \n",
    "    graph_bootstrap = facebook_network.copy()\n",
    "    sample = rn.sample(nodes,porcentaje)\n",
    "    graph_bootstrap.remove_nodes_from(sample)\n",
    "    \n",
    "    xi, xj = [], []\n",
    "    for i,j in graph_bootstrap.edges:\n",
    "        xi.append([graph_bootstrap.nodes[i]['High Income'], graph_bootstrap.nodes[i]['Household Size']])\n",
    "        xj.append([graph_bootstrap.nodes[j]['High Income'], graph_bootstrap.nodes[j]['Household Size']])   \n",
    "    \n",
    "    income = [graph_bootstrap.nodes[i]['High Income'] for i in graph_bootstrap.nodes]    \n",
    "    house  = [graph_bootstrap.nodes[i]['Household Size'] for i in graph_bootstrap.nodes] \n",
    "    corr   = np.cov(income,house)\n",
    "    vi     = np.linalg.inv(corr)        \n",
    "    \n",
    "    distances = [ distance.mahalanobis( xi[i], xj[i], vi ) for i in range(len(xj)) ]\n",
    "    \n",
    "    mahalanobi_distance = sum(distances)/len(distances)\n",
    "    random_distance = 1.7\n",
    "    social_selection = round(1 - mahalanobi_distance / random_distance, 2)\n",
    "    \n",
    "    \n",
    "    df_parameters = df_parameters.append({'Years': '2015-2018', 'Data': 'Empirical Social Selection', 'Parameter value' : social_selection, 'Realization' : realization}, ignore_index = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "######################################################################################################################\n",
    "######################################################################################################################\n",
    "######################################################################################################################\n",
    "######################################################################################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BOOTSTRAP METHOD TO MEASURE EMPIRICAL SOCIAL INFLUENCE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "porcentaje = int(0.3 * facebook_network.number_of_nodes())\n",
    "nodes = [each_node for each_node in facebook_network.nodes()]\n",
    "\n",
    "\n",
    "for realization in range(1,1000):\n",
    "    \n",
    "    graph_bootstrap = facebook_network.copy()\n",
    "    sample = rn.sample(nodes,porcentaje)\n",
    "    graph_bootstrap.remove_nodes_from(sample)\n",
    "\n",
    "    hesitancy_distribution = [graph_bootstrap.nodes[n]['Hesitancy Level before'] for n in graph_bootstrap.nodes()]\n",
    "    \n",
    "    increasing_nodes = [each_node for each_node in graph_bootstrap.nodes if (graph_bootstrap.nodes[each_node]['Hesitancy Level before'] < graph_bootstrap.nodes[each_node]['Hesitancy Level after']) ]\n",
    "    \n",
    "    number_on_increasing_nodes = len(increasing_nodes)\n",
    "    \n",
    "    fraction = [((sum([(graph_bootstrap.nodes[each_neighbor]['Hesitancy Level before']) for each_neighbor in graph_bootstrap.neighbors(each_node)]) + graph_bootstrap.nodes[each_node]['Hesitancy Level before']) / (graph_bootstrap.degree(each_node) + 1)) for each_node in increasing_nodes]\n",
    "    \n",
    "    multiplier = np.percentile(np.array(hesitancy_distribution),95)\n",
    "\n",
    "    influence_value = sum(fraction) / len(fraction) / multiplier    \n",
    "\n",
    "    df_parameters  = df_parameters.append({'Years': '2015-2018', 'Data': 'Empirical Social Influence', 'Parameter value' : influence_value, 'Realization' : realization}, ignore_index = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "######################################################################################################################\n",
    "######################################################################################################################\n",
    "######################################################################################################################\n",
    "######################################################################################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BOOTSTRAP METHOD TO MEASURE EMPIRICAL SPATIAL CLUSTERING 2018"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "porcentaje = int(0.3 * spatial_network.number_of_nodes())\n",
    "nodes = [each_node for each_node in spatial_network.nodes()]\n",
    "\n",
    "for rea in range(1,1000):\n",
    "    \n",
    "    graph_bootstrap = spatial_network.copy()\n",
    "    sample = rn.sample(nodes,porcentaje)\n",
    "    graph_bootstrap.remove_nodes_from(sample)\n",
    "    \n",
    "    SC = nx.attribute_assortativity_coefficient(graph_bootstrap,'Opinion Level after')\n",
    "\n",
    "    df_parameters  = df_parameters.append({'Years': '2015-2018', 'Data': 'Empirical Spatial Clustering', 'Parameter value' : SC, 'Realization' : realization}, ignore_index = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "######################################################################################################################\n",
    "######################################################################################################################\n",
    "######################################################################################################################\n",
    "######################################################################################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SIMULATED SPATIAL CLUSTERING 2015-2018"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "influence = df_parameters[df_parameters['Data'] == 'Empirical Spatial Clustering']['Parameter value'].mean() * multiplier\n",
    "vulnerables_after = len([each_node for each_node in facebook_network.nodes if facebook_network.nodes[each_node]['Opinion Level after'] == 'Vulnerable'])\n",
    "jump = 0.01\n",
    "cutoff = 0.05\n",
    "\n",
    "for rea in range(1,1000,1):\n",
    "\n",
    "    graph = facebook_network.copy()\n",
    "    graph_regular = spatial_network.copy()\n",
    "    \n",
    "    protected = [each_node for each_node in graph.nodes if graph.nodes[each_node]['Opinion Level before'] == 'Protected']\n",
    "    vulnerable = [each_node for each_node in graph.nodes if graph.nodes[each_node]['Opinion Level before'] == 'Vulnerable']\n",
    "    \n",
    "    noisy_nodes = [] \n",
    "    nodes_to_change = 2\n",
    "    noisy_interval = 4\n",
    "    time = 0\n",
    "    \n",
    "    while True:\n",
    "        \n",
    "        index = 0\n",
    "\n",
    "        protected = [each_node for each_node in graph.nodes if graph.nodes[each_node]['Opinion Level before'] == 'Protected']\n",
    "        vulnerables = [each_node for each_node in graph.nodes if graph.nodes[each_node]['Opinion Level before'] == 'Vulnerable']\n",
    "        \n",
    "        fraction = [ [each_node, ((sum([(graph.nodes[each_neighbor]['Hesitancy Level before']) for each_neighbor in graph.neighbors(each_node)])+graph.nodes[each_node]['Hesitancy Level before']) / (graph.degree(each_node)+1))] for each_node in graph.nodes ]\n",
    "        result = [ [x,y] for x, y in fraction if (influence < y) ] \n",
    "        result.sort(key = lambda x: x[1], reverse = True)\n",
    "        \n",
    "        vulnerables_increasing = [each_node for each_node, refusal in result if graph.nodes[each_node]['Opinion Level before'] == 'Vulnerable']\n",
    "        for each_node in vulnerables_increasing: graph.nodes[each_node]['Hesitancy Level before'] = graph.nodes[each_node]['Hesitancy Level before'] + jump\n",
    "\n",
    "        protected_increasing = [each_node for each_node, refusal in result if (graph.nodes[each_node]['Opinion Level before'] == 'Protected' and graph.nodes[each_node]['Hesitancy Level before'] + jump < cutoff)]\n",
    "        for each_node in protected_increasing: graph.nodes[each_node]['Hesitancy Level before'] = graph.nodes[each_node]['Hesitancy Level before'] + jump\n",
    "\n",
    "        protected_changing = [each_node for each_node, refusal in result if \\\n",
    "                                (graph.nodes[each_node]['Opinion Level before'] == 'Protected' and \\\n",
    "                                 graph.nodes[each_node]['Hesitancy Level before'] + jump >= cutoff)]\n",
    "        \n",
    "        for each_node in protected_changing:\n",
    "            if (len(vulnerables) < (vulnerables_after - nodes_to_change)):\n",
    "                graph.nodes[each_node]['Hesitancy Level before'] = graph.nodes[each_node]['Hesitancy Level before'] + jump\n",
    "                graph.nodes[each_node]['Opinion Level before'] = 'Vulnerable'\n",
    "                vulnerables.append(each_node)\n",
    "            else:\n",
    "                noisy_nodes.append(each_node)\n",
    "                index = len(noisy_nodes)\n",
    "\n",
    "        if index >= nodes_to_change:\n",
    "            selected_noisy = rn.sample(noisy_nodes[:noisy_interval],nodes_to_change)            \n",
    "            for each_node in selected_noisy:\n",
    "                graph.nodes[each_node]['Hesitancy Level before'] = graph.nodes[each_node]['Hesitancy Level before'] + jump\n",
    "                graph.nodes[each_node]['Opinion Level before'] = 'Vulnerable'\n",
    "                vulnerables.append(each_node)\n",
    "\n",
    "        protected = [each_node for each_node in graph.nodes if graph.nodes[each_node]['Opinion Level before'] == 'Protected']\n",
    "        vulnerable = [each_node for each_node in graph.nodes if graph.nodes[each_node]['Opinion Level before'] == 'Vulnerable']   \n",
    "\n",
    "        time = time + 1 \n",
    "        if time == 1000 : break \n",
    "        if len(vulnerables) == vulnerables_after : break \n",
    "            \n",
    "    for each_node in graph_regular.nodes: graph_regular.nodes[each_node]['Opinion Level before'] = graph.nodes[each_node]['Opinion Level before']   \n",
    "    spatial_clustering = nx.attribute_assortativity_coefficient(graph_regular,'Opinion Level before')\n",
    "\n",
    "    df_parameters  = df_parameters.append({'Years': '2015-2018', 'Data': 'Simulated Spatial Clustering', 'Parameter value' : spatial_clustering, 'Realization' : realization}, ignore_index = True)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "######################################################################################################################\n",
    "######################################################################################################################\n",
    "######################################################################################################################\n",
    "######################################################################################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PARAMETER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_style(\"whitegrid\")\n",
    "colors = ['#BF96FA','#7B57AD','#7DFA9B','#DFB9AB']\n",
    "ax = sns.pointplot(data = df_parameters, x = \"Data\", y = \"Parameter value\", hue = \"Data\", linestyle = False, palette = colors, err_style ='bars', ci = 'sd', scale = 1.5)\n",
    "plt.xticks([])\n",
    "plt.yticks(fontsize=14)\n",
    "plt.xlabel(\"Parameters\", fontsize=16)\n",
    "plt.ylabel(\"\")\n",
    "plt.legend(title =False,loc=\"upper left\", fontsize=11)\n",
    "ax.figure.savefig('5-Parameters.png',transparent=True,dpi=200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "######################################################################################################################\n",
    "######################################################################################################################\n",
    "######################################################################################################################\n",
    "######################################################################################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MAPS OF COUNTIES STATUS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "year = 2015\n",
    "with urlopen('https://raw.githubusercontent.com/plotly/datasets/master/geojson-counties-fips.json') as response:\n",
    "    counties = json.load(response)   \n",
    "\n",
    "df_hesitancy.FIPS = df_hesitancy.FIPS.astype(float).astype(int).astype(str).str.zfill(5)\n",
    "\n",
    "fig = px.choropleth(df_hesitancy,               \n",
    "                    geojson = counties,\n",
    "                    locations = 'FIPS',\n",
    "                    color = df_hesitancy['Opinion before'],\n",
    "                    color_discrete_map = {'Vulnerable': \"#DEB09E\", 'Protected': \"#418F78\"},\n",
    "                    scope = 'usa'\n",
    "                   )\n",
    "fig.update_layout(legend_title = \"County Status\")\n",
    "fig.update_traces(marker_line_width = 0.1, \n",
    "                  marker_opacity = 0.85, \n",
    "                  marker_line_color = '#262626',\n",
    "                  )\n",
    "fig.write_image(\"4b-\"+str(year)+\".png\", scale = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "year = 2018\n",
    "with urlopen('https://raw.githubusercontent.com/plotly/datasets/master/geojson-counties-fips.json') as response:\n",
    "    counties = json.load(response)   \n",
    "\n",
    "df_hesitancy.FIPS = df_hesitancy.FIPS.astype(float).astype(int).astype(str).str.zfill(5)\n",
    "\n",
    "fig = px.choropleth(df_hesitancy,                 \n",
    "                    geojson = counties,\n",
    "                    locations = 'FIPS',\n",
    "                    color = df_hesitancy['Opinion after'],\n",
    "                    color_discrete_map = {'Vulnerable': \"#DEB09E\", 'Protected': \"#418F78\"},\n",
    "                    scope = 'usa'\n",
    "                   ) \n",
    "fig.update_layout(showlegend = False)\n",
    "fig.update_traces(marker_line_width = 0.1,  \n",
    "                  marker_opacity = 0.85, \n",
    "                  marker_line_color = '#262626',\n",
    "                  )\n",
    "\n",
    "fig.write_image(\"4b-\"+str(year)+\"-empirical.png\", scale = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_simulated = {'FIPS' : [each_node for each_node in graph_regular.nodes],'County Status' : [graph_regular.nodes[each_node]['Opinion Level before'] for each_node in graph_regular.nodes]}\n",
    "df_simulated = pd.DataFrame(dict_simulated )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "year = 2018\n",
    "with urlopen('https://raw.githubusercontent.com/plotly/datasets/master/geojson-counties-fips.json') as response:\n",
    "    counties = json.load(response)   \n",
    "\n",
    "df_simulated.FIPS = df_simulated.FIPS.astype(float).astype(int).astype(str).str.zfill(5)\n",
    "\n",
    "fig = px.choropleth(df_simulated,               \n",
    "                    geojson = counties,\n",
    "                    locations = 'FIPS',\n",
    "                    color = df_simulated['County Status'],\n",
    "                    color_discrete_map = {'Vulnerable': \"#DEB09E\", 'Protected': \"#418F78\"},\n",
    "                    scope = 'usa'\n",
    "                   )\n",
    "fig.update_layout(showlegend = False)\n",
    "fig.update_traces(marker_line_width = 0.1,\n",
    "                  marker_opacity = 0.85, \n",
    "                  marker_line_color = '#262626',\n",
    "                  )\n",
    "\n",
    "fig.write_image(\"4b-\"+str(year)+\"-simulated.png\", scale = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
