{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import random as rn\n",
    "from scipy import stats\n",
    "from scipy.stats import expon\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from urllib.request import urlopen\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_hesitancy = pd.read_csv('Data_sets/US_County_hesitancy.csv',index_col=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_facebook_friendship = pd.read_csv('Data_sets/Facebook_county_network.csv',index_col=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_proximity = pd.read_csv('Data_sets/Proximity_county_network.csv',index_col=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_traits = pd.read_csv('Data_sets/US_County_traits.csv',index_col=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "######################################################################################################################\n",
    "######################################################################################################################\n",
    "######################################################################################################################\n",
    "######################################################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "year_before = 2015\n",
    "year_after = 2018"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TRAITS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_selection = df_traits[df_traits['year'] == year_before][['FIPS','Household Size','High Income Percentage']]\n",
    "df_selection.columns = ['FIPS','Household Size','High Income']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HESITANCY DATA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2015"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_hesitancy_before = df_hesitancy[df_hesitancy['Year'] == year_before][['FIPS','Hesitancy Level']]\n",
    "df_hesitancy_before.columns = ['FIPS','Hesitancy level before']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2018"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_hesitancy_after = df_hesitancy[df_hesitancy['Year'] == year_after][['FIPS','Hesitancy Level']]\n",
    "df_hesitancy_after.columns = ['FIPS','Hesitancy level after']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2015 - 2018"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merge = pd.merge(df_hesitancy_before, df_hesitancy_after, on=\"FIPS\")\n",
    "df_merge['state'] = df_merge['FIPS'].div(1000).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nodes_hesitancy = list(df_merge['FIPS'])\n",
    "\n",
    "hesitancy_before = dict(zip(nodes_hesitancy, list(df_merge['Hesitancy level before'])))\n",
    "hesitancy_after = dict(zip(nodes_hesitancy, list(df_merge['Hesitancy level after'])))\n",
    "\n",
    "opinion_before = dict(zip(nodes_hesitancy, [-1 if each_hesitancy >= 0.05 else 1 for each_node, each_hesitancy in hesitancy_before.items()]))\n",
    "opinion_after = dict(zip(nodes_hesitancy, [-1 if each_hesitancy >= 0.05 else 1 for each_node, each_hesitancy in hesitancy_after.items()]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AGGREGATED NETWORK : FACEBOOK + HESITANCY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\"merge facebook with hesitancy data\"\"\"\n",
    "\n",
    "sci_value = 400\n",
    "df_facebook = df_facebook_friendship[(df_facebook_friendship.sci >= sci_value)][['county_origin','county_destination']]\n",
    "graph_facebook = nx.from_pandas_edgelist(df_facebook, source = 'county_origin', target = 'county_destination')\n",
    "graph_facebook.remove_edges_from(list(nx.selfloop_edges(graph_facebook)))\n",
    "graph_facebook.number_of_nodes()\n",
    "degree = 2 * graph_facebook.number_of_edges() / graph_facebook.number_of_nodes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\"remove missing nodes\"\"\"\n",
    "\n",
    "nodes_in_data_not_in_facebook = [each_node for each_node in nodes_hesitancy if each_node not in graph_facebook.nodes]\n",
    "node_in_facebook_not_in_data = [each_node for each_node in graph_facebook.nodes if each_node not in nodes_hesitancy]\n",
    "\n",
    "missing_nodes = list(set().union(nodes_in_data_not_in_facebook, node_in_facebook_not_in_data))\n",
    "graph_facebook.remove_nodes_from(missing_nodes)\n",
    "\n",
    "graph_facebook.number_of_nodes()\n",
    "degree = 2 * graph_facebook.number_of_edges() / graph_facebook.number_of_nodes()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AGGREGATED NETWORK : \n",
    "## PROXIMITY + FACEBOOK + HESITANCY\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_spatial = nx.from_pandas_edgelist(df_proximity, source = 'county_origin', target = 'county_destination')\n",
    "graph_spatial.remove_edges_from(list(nx.selfloop_edges(graph_spatial)))\n",
    "degree = 2 * graph_spatial.number_of_edges() / graph_spatial.number_of_nodes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "node_in_spatial_not_in_aggregated = [n for n in graph_spatial.nodes() if n not in graph_facebook.nodes()]\n",
    "graph_spatial.remove_nodes_from(node_in_spatial_not_in_aggregated)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"\"\" We have the aggregated dataset, by means the facebook and proximity network with the same counties according to the levels of hesitancy avaliable for the years 2015 and 2018. Now we export aggregated files \"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EXPORT FILES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_graph_spatial = nx.to_pandas_edgelist(graph_spatial, nodelist = graph_spatial.nodes())\n",
    "df_graph_spatial = df_graph_spatial[['source', 'target']]\n",
    "df_graph_spatial.to_csv('Data_sets/Aggregated_spatial_network_period_'+str(year_before)+'-'+str(year_after)+'.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_graph_facebook = nx.to_pandas_edgelist(graph_facebook, nodelist = graph_spatial.nodes())\n",
    "df_graph_facebook = df_graph_facebook[['source', 'target']]\n",
    "df_graph_facebook.to_csv('Data_sets/Aggregated_facebook_network_period_'+str(year_before)+'-'+str(year_after)+'.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_hesitancy_levels = df_merge.copy()\n",
    "df_hesitancy_levels = df_hesitancy_levels[df_hesitancy_levels['FIPS'].isin(list((graph_facebook.nodes())))]\n",
    "df_hesitancy_levels['Opinion before'] = np.where(df_hesitancy_levels['Hesitancy level before'] >= 0.05, 'Vulnerable', 'Protected')\n",
    "df_hesitancy_levels['Opinion after'] = np.where(df_hesitancy_levels['Hesitancy level after'] >= 0.05, 'Vulnerable', 'Protected')\n",
    "df_hesitancy_levels.to_csv('Data_sets/Aggregated_network_hesitancy_level_period_'+str(year_before)+'-'+str(year_after)+'.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_attributes = df_selection.copy()\n",
    "df_attributes = df_attributes[df_attributes['FIPS'].isin(list((graph_facebook.nodes())))]\n",
    "df_attributes.to_csv('Data_sets/Aggregated_network_attributes_period_'+str(year_before)+'.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
